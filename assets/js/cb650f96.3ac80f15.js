"use strict";(self.webpackChunkfalkens_notebook=self.webpackChunkfalkens_notebook||[]).push([[7024],{7669:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"basic-concepts/glossary","title":"Definiciones","description":"Definiciones de conceptos relacionados con la inteligencia artificial (IA).","source":"@site/docs/basic-concepts/glossary.md","sourceDirName":"basic-concepts","slug":"/basic-concepts/glossary","permalink":"/falkens-notebook/docs/basic-concepts/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/falkenslab/falkens-notebook/edit/main/docs/basic-concepts/glossary.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Conceptos b\xe1sicos","permalink":"/falkens-notebook/docs/category/conceptos-b\xe1sicos"},"next":{"title":"Casos de uso","permalink":"/falkens-notebook/docs/category/casos-de-uso"}}');var i=a(4848),r=a(8453);const o={},l="Definiciones",d={},c=[{value:"A",id:"a",level:2},{value:"Agente IA",id:"agente-ia",level:3},{value:"B",id:"b",level:2},{value:"Base de datos vectorial",id:"base-de-datos-vectorial",level:3},{value:"E",id:"e",level:2},{value:"Embeddings",id:"embeddings",level:3},{value:"Entrenamiento (training)",id:"entrenamiento-training",level:3},{value:"F",id:"f",level:2},{value:"Few\u2011shot",id:"fewshot",level:3},{value:"Fine\u2011tuning",id:"finetuning",level:3},{value:"I",id:"i",level:2},{value:"Inferencia",id:"inferencia",level:3},{value:"Inteligencia Artificial (IA)",id:"inteligencia-artificial-ia",level:3},{value:"L",id:"l",level:2},{value:"LangChain",id:"langchain",level:3},{value:"Langflow",id:"langflow",level:3},{value:"Large Language Model (LLM)",id:"large-language-model-llm",level:3},{value:"M",id:"m",level:2},{value:"Modelo de lenguaje",id:"modelo-de-lenguaje",level:3},{value:"P",id:"p",level:2},{value:"Par\xe1metros",id:"par\xe1metros",level:3},{value:"Prompt",id:"prompt",level:3},{value:"R",id:"r",level:2},{value:"RAG",id:"rag",level:3},{value:"T",id:"t",level:2},{value:"Temperatura",id:"temperatura",level:3},{value:"Top\u2011p (nucleus)",id:"topp-nucleus",level:3},{value:"Top\u2011k",id:"topk",level:3},{value:"Token",id:"token",level:3},{value:"V",id:"v",level:2},{value:"Vector",id:"vector",level:3},{value:"Ventana de contexto",id:"ventana-de-contexto",level:3}];function t(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"definiciones",children:"Definiciones"})}),"\n",(0,i.jsx)(n.p,{children:"Definiciones de conceptos relacionados con la inteligencia artificial (IA)."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,i.jsx)(n.h3,{id:"agente-ia",children:"Agente IA"}),"\n",(0,i.jsx)(n.p,{children:"Programa que usa IA para conseguir una meta. Observa informaci\xf3n, decide qu\xe9 hacer y lo ejecuta de forma autom\xe1tica, a veces usando herramientas como un buscador, un calendario o una API."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Qu\xe9 puede hacer: dividir una tarea en pasos, pedir m\xe1s datos, usar una herramienta, recordar cosas simples."}),"\n",(0,i.jsx)(n.li,{children:"Riesgos: equivocarse o repetir pasos. Se reduce poniendo l\xedmites, revisando los resultados y trabajando en un entorno seguro."}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Ver tambi\xe9n: ",(0,i.jsx)(n.a,{href:"#rag",children:"RAG"}),", ",(0,i.jsx)(n.a,{href:"#large-language-model-llm",children:"LLM"}),", ",(0,i.jsx)(n.a,{href:"#prompt",children:"Prompt"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,i.jsx)(n.h3,{id:"base-de-datos-vectorial",children:"Base de datos vectorial"}),"\n",(0,i.jsx)(n.p,{children:"Es como una biblioteca donde los textos o im\xe1genes se guardan como \u201chuellas digitales\u201d num\xe9ricas. Permite buscar por parecido, no solo por palabras exactas."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Para qu\xe9 sirve: encontrar documentos relacionados, responder preguntas y hacer recomendaciones."}),"\n",(0,i.jsx)(n.li,{children:"Ejemplos: FAISS, Milvus, Qdrant, Weaviate, Pinecone, pgvector."}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Ver tambi\xe9n: ",(0,i.jsx)(n.a,{href:"#embeddings",children:"Embeddings"}),", ",(0,i.jsx)(n.a,{href:"#rag",children:"RAG"}),", ",(0,i.jsx)(n.a,{href:"#vector",children:"Vector"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"e",children:"E"}),"\n",(0,i.jsx)(n.h3,{id:"embeddings",children:"Embeddings"}),"\n",(0,i.jsx)(n.p,{children:"La \u201chuella digital\u201d en n\xfameros de un texto, imagen o audio. Con esa huella podemos medir qu\xe9 tan parecidos son dos elementos."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Usos: buscar por significado, agrupar por temas, recomendar contenidos."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"entrenamiento-training",children:"Entrenamiento (training)"}),"\n",(0,i.jsx)(n.p,{children:"Es \u201cense\xf1ar\u201d a un modelo con muchos ejemplos hasta que acierte cada vez m\xe1s. Requiere buenos datos y tiempo de c\xf3mputo."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Variantes: afinar un modelo ya hecho con tus datos; mejorar con correcciones humanas."}),"\n",(0,i.jsx)(n.li,{children:"Buenas pr\xe1cticas: separar datos para probar, parar a tiempo y vigilar resultados."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"f",children:"F"}),"\n",(0,i.jsx)(n.h3,{id:"fewshot",children:"Few\u2011shot"}),"\n",(0,i.jsx)(n.p,{children:"Poner 1\u20133 ejemplos dentro del mensaje para que el modelo copie el estilo o el formato, sin tener que re\u2011entrenarlo."}),"\n",(0,i.jsx)(n.h3,{id:"finetuning",children:"Fine\u2011tuning"}),"\n",(0,i.jsx)(n.p,{children:"Ajustar un modelo con tus propios datos para que se especialice en tu caso. Suele ser m\xe1s preciso que solo dar ejemplos, pero tambi\xe9n m\xe1s costoso."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,i.jsx)(n.h3,{id:"inferencia",children:"Inferencia"}),"\n",(0,i.jsx)(n.p,{children:"Momento en el que el modelo ya entrenado responde o hace una predicci\xf3n."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Lo que importa: que responda r\xe1pido, bien y de forma econ\xf3mica."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"inteligencia-artificial-ia",children:"Inteligencia Artificial (IA)"}),"\n",(0,i.jsx)(n.p,{children:"Tecnolog\xeda que busca que las m\xe1quinas hagan tareas que requieren \u201cinteligencia\u201d: ver, entender lenguaje, decidir, aprender o crear contenido."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,i.jsx)(n.h3,{id:"langchain",children:"LangChain"}),"\n",(0,i.jsx)(n.p,{children:"Framework para crear aplicaciones con modelos de lenguaje (LLM) de forma modular. Proporciona componentes reutilizables (cadenas, agentes, herramientas, memoria) para orquestar prompts, llamadas a modelos, recuperaci\xf3n en bases de datos vectoriales y flujos de decisi\xf3n."}),"\n",(0,i.jsx)(n.p,{children:"Permite:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Componer pipelines de NLP/IA generativa con pasos encadenados."}),"\n",(0,i.jsx)(n.li,{children:"Integrar m\xfaltiples proveedores de LLM y de almacenamiento vectorial."}),"\n",(0,i.jsx)(n.li,{children:"Construir agentes con herramientas (b\xfasqueda, c\xf3digo, APIs) y memoria conversacional."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Se usa como base en muchos proyectos no\u2011code/low\u2011code y entornos visuales."}),"\n",(0,i.jsx)(n.h3,{id:"langflow",children:"Langflow"}),"\n",(0,i.jsx)(n.p,{children:"Entorno visual (low\u2011code/no\u2011code) para dise\xf1ar, probar y desplegar flujos con LLMs y agentes a partir de bloques. Est\xe1 inspirado en la filosof\xeda de LangChain y permite arrastrar y conectar nodos para construir aplicaciones de IA sin escribir mucho c\xf3digo."}),"\n",(0,i.jsx)(n.p,{children:"Caracter\xedsticas clave:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Nodos: LLMs, prompts, herramientas, memoria, RAG, evaluadores, etc."}),"\n",(0,i.jsx)(n.li,{children:"Integraciones: m\xfaltiples proveedores de LLM y bases de datos vectoriales."}),"\n",(0,i.jsx)(n.li,{children:"Iteraci\xf3n r\xe1pida: ejecuci\xf3n parcial de flujos, inspecci\xf3n de entradas/salidas y m\xe9tricas."}),"\n",(0,i.jsx)(n.li,{children:"Portabilidad: exportaci\xf3n/importaci\xf3n de flujos (JSON) y opciones para generar c\xf3digo."}),"\n",(0,i.jsx)(n.li,{children:"Despliegue: ejecuci\xf3n local o en servidor para exponer endpoints."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Casos t\xedpicos: chatbots con recuperaci\xf3n (RAG), asistentes con herramientas, pipelines de clasificaci\xf3n/extracci\xf3n y prototipado r\xe1pido de experiencias con LLM."}),"\n",(0,i.jsx)(n.h3,{id:"large-language-model-llm",children:"Large Language Model (LLM)"}),"\n",(0,i.jsx)(n.p,{children:"Es un modelo de IA muy grande que sabe trabajar con texto: leer, resumir, escribir y contestar preguntas."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ventajas: sirve para muchas tareas con el mismo modelo."}),"\n",(0,i.jsx)(n.li,{children:"L\xedmites: puede inventar datos o no saber lo m\xe1s reciente si no se le da."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,i.jsx)(n.h3,{id:"modelo-de-lenguaje",children:"Modelo de lenguaje"}),"\n",(0,i.jsx)(n.p,{children:"Programa que aprende a predecir la siguiente palabra de un texto. Con esa habilidad puede escribir textos completos y responder preguntas."}),"\n",(0,i.jsxs)(n.p,{children:["Ver tambi\xe9n ",(0,i.jsx)(n.a,{href:"#large-language-model-llm",children:"LLM"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,i.jsx)(n.h3,{id:"par\xe1metros",children:"Par\xe1metros"}),"\n",(0,i.jsx)(n.p,{children:"\u201cPerillas internas\u201d del modelo que se ajustan al aprender. A m\xe1s perillas, m\xe1s capacidad, pero tambi\xe9n m\xe1s coste de c\xf3mputo."}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Ejemplo: Llama 3 8B \u2248 8 mil millones de par\xe1metros."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"prompt",children:"Prompt"}),"\n",(0,i.jsx)(n.p,{children:"El mensaje que enviamos al modelo con instrucciones, contexto y ejemplos."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Consejos: s\xe9 claro, indica pasos, muestra ejemplos y el formato deseado."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,i.jsx)(n.h3,{id:"rag",children:"RAG"}),"\n",(0,i.jsxs)(n.p,{children:["RAG son las siglas de ",(0,i.jsx)(n.strong,{children:"Retrieval-Augmented Generation"})," (Generaci\xf3n Aumentada por Recuperaci\xf3n)."]}),"\n",(0,i.jsx)(n.p,{children:"Es la manera de hacer que el modelo consulte documentos u otra informaci\xf3n antes de responder."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Buscar trozos de texto relacionados."}),"\n",(0,i.jsx)(n.li,{children:"A\xf1adirlos a la pregunta."}),"\n",(0,i.jsx)(n.li,{children:"Responder usando ese contexto."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Ventaja: respuestas m\xe1s actualizadas y con menos \u201cinventos\u201d."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,i.jsx)(n.h3,{id:"temperatura",children:"Temperatura"}),"\n",(0,i.jsx)(n.p,{children:"Controla lo creativo que es el modelo."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Baja"})," (0\u20130.3): respuestas m\xe1s seguras y deterministas."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Alta"})," (0.7\u20131.0): respuestas m\xe1s creativas y aleatorias."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"topp-nucleus",children:"Top\u2011p (nucleus)"}),"\n",(0,i.jsx)(n.p,{children:"Es un par\xe1metro que permite muestrear entre las palabras m\xe1s probables que, juntas, suman un porcentaje (por ejemplo, 90%)."}),"\n",(0,i.jsxs)(n.p,{children:["Por ejemplo, si se establece ",(0,i.jsx)(n.code,{children:"top-p=0.9"}),", el modelo considerar\xe1 solo las palabras que, en conjunto, tienen una probabilidad del 90% de ser la siguiente palabra."]}),"\n",(0,i.jsx)(n.h3,{id:"topk",children:"Top\u2011k"}),"\n",(0,i.jsxs)(n.p,{children:["Es un par\xe1metro que limita la b\xfasqueda a las k palabras m\xe1s probables (por ejemplo, ",(0,i.jsx)(n.code,{children:"top-k=20"}),")."]}),"\n",(0,i.jsx)(n.h3,{id:"token",children:"Token"}),"\n",(0,i.jsx)(n.p,{children:"Pedacitos en los que el modelo divide el texto (parecido a s\xedlabas/palabras). Los l\xedmites y costes se miden con tokens."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,i.jsx)(n.h3,{id:"vector",children:"Vector"}),"\n",(0,i.jsx)(n.p,{children:"Lista de n\xfameros que representa algo, como la \u201chuella digital\u201d de un texto."}),"\n",(0,i.jsx)(n.h3,{id:"ventana-de-contexto",children:"Ventana de contexto"}),"\n",(0,i.jsx)(n.p,{children:"Cantidad de texto que el modelo puede \u201ctener a la vista\u201d de una vez (entrada + respuesta). Si es grande, puede leer m\xe1s, pero consume m\xe1s recursos."})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(t,{...e})}):t(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>l});var s=a(6540);const i={},r=s.createContext(i);function o(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);